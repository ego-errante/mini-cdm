{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d65b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Gas Benchmark Analysis Script\n",
    "\n",
    "This script analyzes the gas benchmark results from GasBenchmark.ts\n",
    "and builds a linear regression model to estimate gas costs.\n",
    "\n",
    "Usage:\n",
    "    python analyze_gas_results.py gas_benchmark_results.csv\n",
    "\n",
    "Requirements:\n",
    "    pip install pandas scikit-learn matplotlib seaborn\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def load_and_prepare_data(csv_path):\n",
    "    \"\"\"Load CSV and prepare features for regression\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Loading data...\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded {len(df)} test cases\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    \n",
    "    # Map filter complexity to approximate bytecode lengths\n",
    "    filter_bytecode_map = {\n",
    "        'none': 0,\n",
    "        'simple': 7,\n",
    "        'medium': 15,\n",
    "        'complex': 30\n",
    "    }\n",
    "    df['FilterBytes'] = df['FilterComplexity'].map(filter_bytecode_map)\n",
    "    \n",
    "    print(f\"\\nData preview:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_basic_statistics(df):\n",
    "    \"\"\"Print basic statistics about gas costs\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Basic Statistics\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(\"Total Gas by Operation:\")\n",
    "    print(df.groupby('Operation')['TotalGas'].agg(['mean', 'min', 'max', 'std']))\n",
    "    \n",
    "    print(\"\\n\\nTotal Gas by Filter Complexity:\")\n",
    "    print(df.groupby('FilterComplexity')['TotalGas'].agg(['mean', 'min', 'max']))\n",
    "    \n",
    "    print(\"\\n\\nGas Phase Breakdown (averages):\")\n",
    "    print(f\"  OpenJob:       {df['OpenJobGas'].mean():,.0f} gas ({df['OpenJobGas'].mean()/df['TotalGas'].mean()*100:.1f}%)\")\n",
    "    print(f\"  PushRow Total: {df['PushRowTotal'].mean():,.0f} gas ({df['PushRowTotal'].mean()/df['TotalGas'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Finalize:      {df['FinalizeGas'].mean():,.0f} gas ({df['FinalizeGas'].mean()/df['TotalGas'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Total:         {df['TotalGas'].mean():,.0f} gas\")\n",
    "\n",
    "def build_regression_model(df, target='TotalGas', include_interaction=True):\n",
    "    \"\"\"Build linear regression model\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Building Regression Model for {target}\")\n",
    "    if include_interaction:\n",
    "        print(\"(with Rows × Columns interaction)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Prepare features\n",
    "    X = df[['Rows', 'Columns', 'FilterBytes']].copy()\n",
    "    \n",
    "    # Add interaction term (key insight: decoding cost scales with rows × columns)\n",
    "    if include_interaction:\n",
    "        X['Rows_x_Columns'] = df['Rows'] * df['Columns']\n",
    "    \n",
    "    # Add operation dummy variables (COUNT is reference category)\n",
    "    # Create operation dummies with COUNT as explicit reference\n",
    "    operation_dummies = pd.get_dummies(df['Operation'], prefix='Op')\n",
    "    # Drop COUNT column to make it the reference category\n",
    "    operation_dummies = operation_dummies.drop('Op_COUNT', axis=1)\n",
    "    X = pd.concat([X, operation_dummies], axis=1)\n",
    "    \n",
    "    y = df[target]\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Predictions and metrics\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y, y_pred) * 100\n",
    "    \n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"  R² Score:  {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "    print(f\"  MAPE:      {mape:.2f}%\")\n",
    "    print(f\"  Target:    R² ≥ 0.60, MAPE ≤ 40%\")\n",
    "    \n",
    "    if r2 >= 0.60:\n",
    "        print(f\"  ✓ Model meets R² target!\")\n",
    "    else:\n",
    "        print(f\"  ✗ Model below R² target\")\n",
    "    \n",
    "    if mape <= 40:\n",
    "        print(f\"  ✓ Model meets MAPE target!\")\n",
    "    else:\n",
    "        print(f\"  ✗ Model above MAPE target - consider more terms\")\n",
    "    \n",
    "    # Print coefficients\n",
    "    print(f\"\\nModel Coefficients:\")\n",
    "    print(f\"  Intercept: {model.intercept_:,.0f} gas\")\n",
    "    \n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Coefficient': model.coef_,\n",
    "        'Impact': model.coef_\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + coef_df.to_string(index=False))\n",
    "    \n",
    "    return model, X, y, y_pred, coef_df\n",
    "\n",
    "def analyze_per_row_costs(df):\n",
    "    \"\"\"Analyze per-row costs by operation\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Per-Row Cost Analysis\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(\"Average gas per row by operation:\")\n",
    "    per_row = df.groupby('Operation')['PushRowAvg'].agg(['mean', 'std'])\n",
    "    print(per_row)\n",
    "    \n",
    "    # Calculate relative costs (COUNT = baseline)\n",
    "    baseline = per_row.loc['COUNT', 'mean']\n",
    "    per_row['Relative'] = per_row['mean'] / baseline\n",
    "    \n",
    "    print(\"\\nRelative to COUNT (1.0x):\")\n",
    "    print(per_row[['Relative']].sort_values('Relative', ascending=False))\n",
    "\n",
    "def visualize_results(df, y_pred, coef_df):\n",
    "    \"\"\"Create visualization plots\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Generating Visualizations\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    ax = axes[0, 0]\n",
    "    ax.scatter(df['TotalGas'], y_pred, alpha=0.6)\n",
    "    ax.plot([df['TotalGas'].min(), df['TotalGas'].max()], \n",
    "            [df['TotalGas'].min(), df['TotalGas'].max()], \n",
    "            'r--', lw=2)\n",
    "    ax.set_xlabel('Actual Gas')\n",
    "    ax.set_ylabel('Predicted Gas')\n",
    "    ax.set_title('Actual vs Predicted Total Gas')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Gas by Operation\n",
    "    ax = axes[0, 1]\n",
    "    df.boxplot(column='TotalGas', by='Operation', ax=ax)\n",
    "    ax.set_xlabel('Operation')\n",
    "    ax.set_ylabel('Total Gas')\n",
    "    ax.set_title('Gas Distribution by Operation')\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 3. Coefficient Importance\n",
    "    ax = axes[1, 0]\n",
    "    coef_plot = coef_df.head(10).copy()\n",
    "    ax.barh(coef_plot['Feature'], coef_plot['Coefficient'])\n",
    "    ax.set_xlabel('Coefficient (Gas Impact)')\n",
    "    ax.set_title('Top 10 Feature Coefficients')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Gas Scaling with Rows\n",
    "    ax = axes[1, 1]\n",
    "    for op in df['Operation'].unique():\n",
    "        op_data = df[df['Operation'] == op]\n",
    "        ax.scatter(op_data['Rows'], op_data['TotalGas'], label=op, alpha=0.6)\n",
    "    ax.set_xlabel('Number of Rows')\n",
    "    ax.set_ylabel('Total Gas')\n",
    "    ax.set_title('Gas Scaling with Rows (by Operation)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gas_analysis.png', dpi=150)\n",
    "    print(\"Saved visualization to: gas_analysis.png\")\n",
    "\n",
    "def generate_estimator_code(model, coef_df):\n",
    "    \"\"\"Generate TypeScript estimator function code\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Gas Estimator Function (TypeScript)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Extract coefficients\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Find row, column, filter coefficients\n",
    "    row_coef = coef_df[coef_df['Feature'] == 'Rows']['Coefficient'].values[0] if 'Rows' in coef_df['Feature'].values else 0\n",
    "    col_coef = coef_df[coef_df['Feature'] == 'Columns']['Coefficient'].values[0] if 'Columns' in coef_df['Feature'].values else 0\n",
    "    filter_coef = coef_df[coef_df['Feature'] == 'FilterBytes']['Coefficient'].values[0] if 'FilterBytes' in coef_df['Feature'].values else 0\n",
    "    \n",
    "    # Check for interaction term\n",
    "    interaction_coef = 0\n",
    "    has_interaction = 'Rows_x_Columns' in coef_df['Feature'].values\n",
    "    if has_interaction:\n",
    "        interaction_coef = coef_df[coef_df['Feature'] == 'Rows_x_Columns']['Coefficient'].values[0]\n",
    "    \n",
    "    # Extract operation coefficients\n",
    "    op_coefs = {}\n",
    "    for _, row in coef_df.iterrows():\n",
    "        if row['Feature'].startswith('Op_'):\n",
    "            op_name = row['Feature'].replace('Op_', '')\n",
    "            op_coefs[op_name] = row['Coefficient']\n",
    "    \n",
    "    # Generate code with or without interaction\n",
    "    if has_interaction:\n",
    "        code = f\"\"\"\n",
    "/**\n",
    " * Estimates gas cost for a JobManager job based on parameters\n",
    " * \n",
    " * Model Accuracy: See analysis output for R² and MAPE\n",
    " * Model includes Rows × Columns interaction term for better accuracy\n",
    " * \n",
    " * @param rows Number of rows in dataset\n",
    " * @param columns Number of columns in dataset\n",
    " * @param operation Operation type\n",
    " * @param filterBytes Approximate filter bytecode length\n",
    " * @returns Estimated total gas cost\n",
    " */\n",
    "function estimateJobGas(\n",
    "  rows: number,\n",
    "  columns: number,\n",
    "  operation: 'COUNT' | 'SUM' | 'AVG_P' | 'WEIGHTED_SUM' | 'MIN' | 'MAX',\n",
    "  filterBytes: number\n",
    "): number {{\n",
    "  // Base cost (intercept)\n",
    "  let gas = {intercept:.0f};\n",
    "  \n",
    "  // Add per-row cost\n",
    "  gas += rows * {row_coef:.0f};\n",
    "  \n",
    "  // Add per-column cost\n",
    "  gas += columns * {col_coef:.0f};\n",
    "  \n",
    "  // Add row × column interaction (decoding cost scales with both)\n",
    "  gas += (rows * columns) * {interaction_coef:.0f};\n",
    "  \n",
    "  // Add filter complexity cost\n",
    "  gas += filterBytes * {filter_coef:.0f};\n",
    "  \n",
    "  // Add operation-specific costs (relative to COUNT baseline)\n",
    "  const operationCosts = {{\n",
    "    'COUNT': 0,  // baseline\n",
    "    'SUM': {op_coefs.get('SUM', 0):.0f},\n",
    "    'AVG_P': {op_coefs.get('AVG_P', 0):.0f},\n",
    "    'WEIGHTED_SUM': {op_coefs.get('WEIGHTED_SUM', 0):.0f},\n",
    "    'MIN': {op_coefs.get('MIN', 0):.0f},\n",
    "    'MAX': {op_coefs.get('MAX', 0):.0f},\n",
    "  }};\n",
    "  \n",
    "  gas += operationCosts[operation];\n",
    "  \n",
    "  return Math.round(gas);\n",
    "}}\n",
    "\n",
    "// Example usage:\n",
    "const estimatedGas = estimateJobGas(50, 15, 'SUM', 7);\n",
    "console.log(`Estimated gas: ${{estimatedGas.toLocaleString()}}`);\n",
    "\"\"\"\n",
    "    else:\n",
    "        code = f\"\"\"\n",
    "/**\n",
    " * Estimates gas cost for a JobManager job based on parameters\n",
    " * \n",
    " * Model Accuracy: See analysis output for R² and MAPE\n",
    " * \n",
    " * @param rows Number of rows in dataset\n",
    " * @param columns Number of columns in dataset\n",
    " * @param operation Operation type\n",
    " * @param filterBytes Approximate filter bytecode length\n",
    " * @returns Estimated total gas cost\n",
    " */\n",
    "function estimateJobGas(\n",
    "  rows: number,\n",
    "  columns: number,\n",
    "  operation: 'COUNT' | 'SUM' | 'AVG_P' | 'WEIGHTED_SUM' | 'MIN' | 'MAX',\n",
    "  filterBytes: number\n",
    "): number {{\n",
    "  // Base cost (intercept)\n",
    "  let gas = {intercept:.0f};\n",
    "  \n",
    "  // Add per-row cost\n",
    "  gas += rows * {row_coef:.0f};\n",
    "  \n",
    "  // Add per-column cost (decoding)\n",
    "  gas += columns * {col_coef:.0f};\n",
    "  \n",
    "  // Add filter complexity cost\n",
    "  gas += filterBytes * {filter_coef:.0f};\n",
    "  \n",
    "  // Add operation-specific costs (relative to COUNT baseline)\n",
    "  const operationCosts = {{\n",
    "    'COUNT': 0,  // baseline\n",
    "    'SUM': {op_coefs.get('SUM', 0):.0f},\n",
    "    'AVG_P': {op_coefs.get('AVG_P', 0):.0f},\n",
    "    'WEIGHTED_SUM': {op_coefs.get('WEIGHTED_SUM', 0):.0f},\n",
    "    'MIN': {op_coefs.get('MIN', 0):.0f},\n",
    "    'MAX': {op_coefs.get('MAX', 0):.0f},\n",
    "  }};\n",
    "  \n",
    "  gas += operationCosts[operation];\n",
    "  \n",
    "  return Math.round(gas);\n",
    "}}\n",
    "\n",
    "// Example usage:\n",
    "const estimatedGas = estimateJobGas(50, 15, 'SUM', 7);\n",
    "console.log(`Estimated gas: ${{estimatedGas.toLocaleString()}}`);\n",
    "\"\"\"\n",
    "    \n",
    "    print(code)\n",
    "    \n",
    "    # Save to file\n",
    "    with open('estimateJobGas.ts', 'w') as f:\n",
    "        f.write(code)\n",
    "    print(\"\\nSaved estimator function to: estimateJobGas.ts\")\n",
    "\n",
    "def main():\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"Usage: python analyze_gas_results.py <csv_file>\")\n",
    "        print(\"\\nExample: python analyze_gas_results.py gas_benchmark_results.csv\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    csv_path = \"gas_benchmark_results.csv\"\n",
    "    # csv_path = sys.argv[1]\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        df = load_and_prepare_data(csv_path)\n",
    "        \n",
    "        # Basic statistics\n",
    "        analyze_basic_statistics(df)\n",
    "        \n",
    "        # Per-row analysis\n",
    "        analyze_per_row_costs(df)\n",
    "        \n",
    "        # Build regression model\n",
    "        model, X, y, y_pred, coef_df = build_regression_model(df, 'TotalGas')\n",
    "        \n",
    "        # Optionally analyze per-phase costs\n",
    "        print(\"\\n\\n--- Analyzing PushRow Costs ---\")\n",
    "        build_regression_model(df, 'PushRowTotal')\n",
    "        \n",
    "        # Generate visualizations\n",
    "        visualize_results(df, y_pred, coef_df)\n",
    "        \n",
    "        # Generate estimator code\n",
    "        generate_estimator_code(model, coef_df)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Analysis Complete!\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        print(\"Generated files:\")\n",
    "        print(\"  - gas_analysis.png (visualizations)\")\n",
    "        print(\"  - estimateJobGas.ts (estimator function)\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"  1. Review R² score (target: ≥0.60)\")\n",
    "        print(\"  2. Check MAPE (target: ≤40%)\")\n",
    "        print(\"  3. Use estimateJobGas.ts in your application\")\n",
    "        print(\"  4. Validate with holdout test cases\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{csv_path}' not found\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9b280c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOG-TRANSFORMED REGRESSION MODEL\n",
      "================================================================================\n",
      "\n",
      "Model Performance:\n",
      "  R² Score:  0.9091 (90.9% variance explained)\n",
      "  MAPE:      34.27%\n",
      "  Target:    R² ≥ 0.60, MAPE ≤ 40%\n",
      "  ✓ Model meets R² target!\n",
      "  ✓✓✓ Model meets MAPE target! ✓✓✓\n",
      "\n",
      "Log-Scale Model Coefficients:\n",
      "  Intercept: 14.716354 (log gas)\n",
      "\n",
      "        Feature  Coefficient\n",
      "Op_WEIGHTED_SUM     1.050678\n",
      "       Op_AVG_P     0.186049\n",
      "         Op_SUM     0.183671\n",
      "         Op_MAX     0.160466\n",
      "         Op_MIN     0.160352\n",
      "        Columns     0.086790\n",
      "           Rows     0.031711\n",
      "    FilterBytes     0.012810\n",
      " Rows_x_Columns    -0.000556\n",
      "\n",
      "================================================================================\n",
      "Error Analysis by Row Count:\n",
      "================================================================================\n",
      "\n",
      "       PctError                       \n",
      "           mean        min         max\n",
      "Rows                                  \n",
      "5     74.680308  55.735227  117.089075\n",
      "25    23.896922   5.188281   40.343891\n",
      "100   24.979165   7.165950   50.009550\n",
      "\n",
      "================================================================================\n",
      "Negative Predictions Check:\n",
      "================================================================================\n",
      "  ✓ All predictions are positive!\n",
      "\n",
      "================================================================================\n",
      "Sample Predictions (small vs large cases):\n",
      "================================================================================\n",
      "\n",
      "TestID  Rows  Columns Operation  TotalGas    Predicted  PctError\n",
      "  B1-2    25       10     COUNT  17245040 1.233096e+07 28.495633\n",
      " B2-25     5       10     COUNT   4128197 7.309333e+06 77.058726\n",
      " B2-27     5       10       SUM   4754633 8.783048e+06 84.726098\n",
      " B4-49     5        3     COUNT   2478601 4.059637e+06 63.787420\n",
      " B4-58   100       32       SUM 252635087 2.806342e+08 11.082846\n",
      " B4-60   100       32     AVG_P 252691192 2.813022e+08 11.322526\n",
      "\n",
      "================================================================================\n",
      "TYPESCRIPT ESTIMATOR (Log-Transformed Model)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "/**\n",
      " * Estimates gas cost for a JobManager job based on parameters\n",
      " * \n",
      " * Model: Log-transformed linear regression\n",
      " * Accuracy: R² = 0.9091 (90.9%), MAPE = 34.27%\n",
      " * \n",
      " * @param rows Number of rows in dataset\n",
      " * @param columns Number of columns in dataset\n",
      " * @param operation Operation type\n",
      " * @param filterBytes Approximate filter bytecode length (0=none, 7=simple, 15=medium, 30=complex)\n",
      " * @returns Estimated total gas cost\n",
      " */\n",
      "export function estimateJobGas(\n",
      "  rows: number,\n",
      "  columns: number,\n",
      "  operation: 'COUNT' | 'SUM' | 'AVG_P' | 'WEIGHTED_SUM' | 'MIN' | 'MAX',\n",
      "  filterBytes: number\n",
      "): number {\n",
      "  // Log-scale linear model\n",
      "  let logGas = 14.71635363;\n",
      "\n",
      "  // Add feature contributions\n",
      "  logGas += rows * 0.03171097;\n",
      "  logGas += columns * 0.08678983;\n",
      "  logGas += (rows * columns) * -0.00055629;\n",
      "  logGas += filterBytes * 0.01281007;\n",
      "\n",
      "  // Add operation-specific costs (relative to COUNT baseline)\n",
      "  const operationLogCosts = {\n",
      "    'COUNT': 0,  // baseline\n",
      "    'SUM': 0.18367148,\n",
      "    'AVG_P': 0.18604887,\n",
      "    'WEIGHTED_SUM': 1.05067793,\n",
      "    'MIN': 0.16035151,\n",
      "    'MAX': 0.16046606,\n",
      "  };\n",
      "\n",
      "  logGas += operationLogCosts[operation];\n",
      "\n",
      "  // Transform back from log scale to gas units\n",
      "  const gas = Math.exp(logGas);\n",
      "\n",
      "  return Math.round(gas);\n",
      "}\n",
      "\n",
      "// Example usage:\n",
      "const gas1 = estimateJobGas(5, 3, 'COUNT', 7);    // Small case\n",
      "const gas2 = estimateJobGas(25, 10, 'SUM', 15);   // Medium case\n",
      "const gas3 = estimateJobGas(100, 32, 'AVG_P', 30); // Large case\n",
      "\n",
      "console.log(`Small (5×3 COUNT):    ${gas1.toLocaleString()} gas`);\n",
      "console.log(`Medium (25×10 SUM):   ${gas2.toLocaleString()} gas`);\n",
      "console.log(`Large (100×32 AVG_P): ${gas3.toLocaleString()} gas`);\n",
      "\n",
      "\n",
      "✓ Saved to: estimateJobGas_log.ts\n",
      "\n",
      "================================================================================\n",
      "SUCCESS! Log transformation resolves the MAPE issue.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Gas Benchmark Analysis with LOG TRANSFORMATION\n",
    "\n",
    "This addresses the MAPE issue for small cases by using log-transformed regression.\n",
    "Gas costs span 100x range (2.5M to 250M), so log transformation is appropriate.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Load data\n",
    "csv_path = \"gas_benchmark_results.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Map filter complexity\n",
    "filter_bytecode_map = {'none': 0, 'simple': 7, 'medium': 15, 'complex': 30}\n",
    "df['FilterBytes'] = df['FilterComplexity'].map(filter_bytecode_map)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LOG-TRANSFORMED REGRESSION MODEL\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Prepare features\n",
    "X = df[['Rows', 'Columns', 'FilterBytes']].copy()\n",
    "X['Rows_x_Columns'] = df['Rows'] * df['Columns']\n",
    "\n",
    "# Add operation dummies (COUNT is reference)\n",
    "operation_dummies = pd.get_dummies(df['Operation'], prefix='Op')\n",
    "operation_dummies = operation_dummies.drop('Op_COUNT', axis=1)\n",
    "X = pd.concat([X, operation_dummies], axis=1)\n",
    "\n",
    "# Transform target to log scale (key fix for 100x range)\n",
    "y = df['TotalGas']\n",
    "y_log = np.log(y)\n",
    "\n",
    "# Fit model on log scale\n",
    "model_log = LinearRegression()\n",
    "model_log.fit(X, y_log)\n",
    "\n",
    "# Predict and transform back to original scale\n",
    "y_pred_log = model_log.predict(X)\n",
    "y_pred = np.exp(y_pred_log)\n",
    "\n",
    "# Calculate metrics on original scale\n",
    "r2 = r2_score(y, y_pred)\n",
    "mape = mean_absolute_percentage_error(y, y_pred) * 100\n",
    "\n",
    "print(f\"Model Performance:\")\n",
    "print(f\"  R² Score:  {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
    "print(f\"  MAPE:      {mape:.2f}%\")\n",
    "print(f\"  Target:    R² ≥ 0.60, MAPE ≤ 40%\")\n",
    "\n",
    "if r2 >= 0.60:\n",
    "    print(f\"  ✓ Model meets R² target!\")\n",
    "else:\n",
    "    print(f\"  ✗ Model below R² target\")\n",
    "\n",
    "if mape <= 40:\n",
    "    print(f\"  ✓✓✓ Model meets MAPE target! ✓✓✓\")\n",
    "else:\n",
    "    print(f\"  ✗ Model above MAPE target\")\n",
    "\n",
    "# Print coefficients\n",
    "print(f\"\\nLog-Scale Model Coefficients:\")\n",
    "print(f\"  Intercept: {model_log.intercept_:.6f} (log gas)\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model_log.coef_\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\n\" + coef_df.to_string(index=False))\n",
    "\n",
    "# Detailed error analysis\n",
    "df['Predicted'] = y_pred\n",
    "df['Error'] = y - y_pred\n",
    "df['PctError'] = np.abs(df['Error'] / y) * 100\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Error Analysis by Row Count:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "by_rows = df.groupby('Rows')[['PctError']].agg(['mean', 'min', 'max'])\n",
    "print(by_rows)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Negative Predictions Check:\")\n",
    "print(f\"{'='*80}\")\n",
    "negative = df[df['Predicted'] < 0]\n",
    "if len(negative) > 0:\n",
    "    print(f\"  ✗ {len(negative)} negative predictions found!\")\n",
    "else:\n",
    "    print(f\"  ✓ All predictions are positive!\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Sample Predictions (small vs large cases):\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "sample = df[df['TestID'].isin(['B4-49', 'B2-25', 'B1-2', 'B2-27', 'B4-60', 'B4-58'])]\n",
    "print(sample[['TestID', 'Rows', 'Columns', 'Operation', 'TotalGas', 'Predicted', 'PctError']].to_string(index=False))\n",
    "\n",
    "# Generate TypeScript estimator with log transformation\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"TYPESCRIPT ESTIMATOR (Log-Transformed Model)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "intercept = model_log.intercept_\n",
    "row_coef = coef_df[coef_df['Feature'] == 'Rows']['Coefficient'].values[0]\n",
    "col_coef = coef_df[coef_df['Feature'] == 'Columns']['Coefficient'].values[0]\n",
    "filter_coef = coef_df[coef_df['Feature'] == 'FilterBytes']['Coefficient'].values[0]\n",
    "interaction_coef = coef_df[coef_df['Feature'] == 'Rows_x_Columns']['Coefficient'].values[0]\n",
    "\n",
    "op_coefs = {}\n",
    "for _, row in coef_df.iterrows():\n",
    "    if row['Feature'].startswith('Op_'):\n",
    "        op_name = row['Feature'].replace('Op_', '')\n",
    "        op_coefs[op_name] = row['Coefficient']\n",
    "\n",
    "ts_code = f\"\"\"\n",
    "/**\n",
    " * Estimates gas cost for a JobManager job based on parameters\n",
    " * \n",
    " * Model: Log-transformed linear regression\n",
    " * Accuracy: R² = {r2:.4f} ({r2*100:.1f}%), MAPE = {mape:.2f}%\n",
    " * \n",
    " * @param rows Number of rows in dataset\n",
    " * @param columns Number of columns in dataset\n",
    " * @param operation Operation type\n",
    " * @param filterBytes Approximate filter bytecode length (0=none, 7=simple, 15=medium, 30=complex)\n",
    " * @returns Estimated total gas cost\n",
    " */\n",
    "export function estimateJobGas(\n",
    "  rows: number,\n",
    "  columns: number,\n",
    "  operation: 'COUNT' | 'SUM' | 'AVG_P' | 'WEIGHTED_SUM' | 'MIN' | 'MAX',\n",
    "  filterBytes: number\n",
    "): number {{\n",
    "  // Log-scale linear model\n",
    "  let logGas = {intercept:.8f};\n",
    "  \n",
    "  // Add feature contributions\n",
    "  logGas += rows * {row_coef:.8f};\n",
    "  logGas += columns * {col_coef:.8f};\n",
    "  logGas += (rows * columns) * {interaction_coef:.8f};\n",
    "  logGas += filterBytes * {filter_coef:.8f};\n",
    "  \n",
    "  // Add operation-specific costs (relative to COUNT baseline)\n",
    "  const operationLogCosts = {{\n",
    "    'COUNT': 0,  // baseline\n",
    "    'SUM': {op_coefs.get('SUM', 0):.8f},\n",
    "    'AVG_P': {op_coefs.get('AVG_P', 0):.8f},\n",
    "    'WEIGHTED_SUM': {op_coefs.get('WEIGHTED_SUM', 0):.8f},\n",
    "    'MIN': {op_coefs.get('MIN', 0):.8f},\n",
    "    'MAX': {op_coefs.get('MAX', 0):.8f},\n",
    "  }};\n",
    "  \n",
    "  logGas += operationLogCosts[operation];\n",
    "  \n",
    "  // Transform back from log scale to gas units\n",
    "  const gas = Math.exp(logGas);\n",
    "  \n",
    "  return Math.round(gas);\n",
    "}}\n",
    "\n",
    "// Example usage:\n",
    "const gas1 = estimateJobGas(5, 3, 'COUNT', 7);    // Small case\n",
    "const gas2 = estimateJobGas(25, 10, 'SUM', 15);   // Medium case\n",
    "const gas3 = estimateJobGas(100, 32, 'AVG_P', 30); // Large case\n",
    "\n",
    "console.log(`Small (5×3 COUNT):    ${{gas1.toLocaleString()}} gas`);\n",
    "console.log(`Medium (25×10 SUM):   ${{gas2.toLocaleString()}} gas`);\n",
    "console.log(`Large (100×32 AVG_P): ${{gas3.toLocaleString()}} gas`);\n",
    "\"\"\"\n",
    "\n",
    "print(ts_code)\n",
    "\n",
    "with open('estimateJobGas_log.ts', 'w') as f:\n",
    "    f.write(ts_code)\n",
    "\n",
    "print(\"\\n✓ Saved to: estimateJobGas_log.ts\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUCCESS! Log transformation resolves the MAPE issue.\")\n",
    "print(f\"{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ecab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Diagnose MAPE issues by looking at prediction errors\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('gas_benchmark_results.csv')\n",
    "\n",
    "# Map filter complexity\n",
    "filter_bytecode_map = {\n",
    "    'none': 0,\n",
    "    'simple': 7,\n",
    "    'medium': 15,\n",
    "    'complex': 30\n",
    "}\n",
    "df['FilterBytes'] = df['FilterComplexity'].map(filter_bytecode_map)\n",
    "\n",
    "# Prepare features\n",
    "X = df[['Rows', 'Columns', 'FilterBytes']].copy()\n",
    "X['Rows_x_Columns'] = df['Rows'] * df['Columns']\n",
    "\n",
    "# Create operation dummies with COUNT as reference\n",
    "operation_dummies = pd.get_dummies(df['Operation'], prefix='Op')\n",
    "operation_dummies = operation_dummies.drop('Op_COUNT', axis=1)\n",
    "X = pd.concat([X, operation_dummies], axis=1)\n",
    "\n",
    "y = df['TotalGas']\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Calculate errors\n",
    "df['Predicted'] = y_pred\n",
    "df['Error'] = y - y_pred\n",
    "df['AbsError'] = np.abs(df['Error'])\n",
    "df['PctError'] = np.abs(df['Error'] / y) * 100\n",
    "\n",
    "# Overall metrics\n",
    "r2 = r2_score(y, y_pred)\n",
    "mape = mean_absolute_percentage_error(y, y_pred) * 100\n",
    "\n",
    "print(f\"Overall R² = {r2:.4f}, MAPE = {mape:.2f}%\\n\")\n",
    "\n",
    "# Show worst predictions\n",
    "print(\"=\" * 100)\n",
    "print(\"Top 10 Worst Predictions (by % error):\")\n",
    "print(\"=\" * 100)\n",
    "worst = df.nlargest(10, 'PctError')[['TestID', 'Rows', 'Columns', 'Operation', 'FilterComplexity', \n",
    "                                       'TotalGas', 'Predicted', 'Error', 'PctError']]\n",
    "print(worst.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Top 10 Best Predictions (by % error):\")\n",
    "print(\"=\" * 100)\n",
    "best = df.nsmallest(10, 'PctError')[['TestID', 'Rows', 'Columns', 'Operation', 'FilterComplexity', \n",
    "                                      'TotalGas', 'Predicted', 'Error', 'PctError']]\n",
    "print(best.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Error Statistics by Operation:\")\n",
    "print(\"=\" * 100)\n",
    "by_op = df.groupby('Operation')[['PctError', 'AbsError']].agg(['mean', 'std', 'min', 'max'])\n",
    "print(by_op)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Error Statistics by Row Count:\")\n",
    "print(\"=\" * 100)\n",
    "by_rows = df.groupby('Rows')[['PctError', 'AbsError']].agg(['mean', 'std', 'min', 'max'])\n",
    "print(by_rows)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Cases with negative predictions:\")\n",
    "print(\"=\" * 100)\n",
    "negative = df[df['Predicted'] < 0]\n",
    "if len(negative) > 0:\n",
    "    print(negative[['TestID', 'Rows', 'Columns', 'Operation', 'TotalGas', 'Predicted']])\n",
    "else:\n",
    "    print(\"None - all predictions are positive!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Small cases (Rows=5, Columns=3):\")\n",
    "print(\"=\" * 100)\n",
    "small = df[(df['Rows'] == 5) & (df['Columns'] == 3)]\n",
    "print(small[['TestID', 'Operation', 'TotalGas', 'Predicted', 'Error', 'PctError']].to_string(index=False))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
